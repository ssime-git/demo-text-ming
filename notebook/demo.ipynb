{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape de prétraitement des données\n",
    "def preprocess(text):\n",
    "    # Supprimer la ponctuation et les chiffres\n",
    "    text = ''.join([c for c in text if c.isalpha() or c.isspace()])\n",
    "\n",
    "    # Mettre en minuscules\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Supprimer les stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "    # Rejoindre les tokens en une seule chaîne de texte\n",
    "    preprocessed_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "# Étape de représentation des données\n",
    "def represent(texts):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    return X, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textes d'origine :\n",
      "-  Text mining is the process of extracting useful information from unstructured text data.\n",
      "-  The preprocessing step involves cleaning and preparing the text for analysis.\n",
      "-  Representation of the data is important to make it suitable for machine learning algorithms.\n",
      "\n",
      "Textes prétraités :\n",
      "-  text mining process extracting useful information unstructured text data\n",
      "-  preprocessing step involves cleaning preparing text analysis\n",
      "-  representation data important make suitable machine learning algorithm\n",
      "\n",
      "Matrice de termes :\n",
      "[[0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 2 1 1]\n",
      " [0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0]\n",
      " [1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0]]\n",
      "\n",
      "Liste des termes :\n",
      "['algorithm' 'analysis' 'cleaning' 'data' 'extracting' 'important'\n",
      " 'information' 'involves' 'learning' 'machine' 'make' 'mining' 'preparing'\n",
      " 'preprocessing' 'process' 'representation' 'step' 'suitable' 'text'\n",
      " 'unstructured' 'useful']\n"
     ]
    }
   ],
   "source": [
    "# Textes d'exemple\n",
    "texts = [\n",
    "    \"Text mining is the process of extracting useful information from unstructured text data.\",\n",
    "    \"The preprocessing step involves cleaning and preparing the text for analysis.\",\n",
    "    \"Representation of the data is important to make it suitable for machine learning algorithms.\",\n",
    "]\n",
    "\n",
    "# Prétraitement des textes\n",
    "preprocessed_texts = [preprocess(text) for text in texts]\n",
    "\n",
    "# Représentation des données\n",
    "X, feature_names = represent(preprocessed_texts)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Textes d'origine :\")\n",
    "for text in texts:\n",
    "    print(\"- \", text)\n",
    "print(\"\\nTextes prétraités :\")\n",
    "for text in preprocessed_texts:\n",
    "    print(\"- \", text)\n",
    "print(\"\\nMatrice de termes :\")\n",
    "print(X.toarray())\n",
    "print(\"\\nListe des termes :\")\n",
    "print(feature_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les expressions régulières\n",
    "\n",
    "* La fonction `match` tente de trouver la correspondance de l'expression régulière uniquement au début de la chaîne de texte. Si une correspondance est trouvée, elle renvoie un objet Match, sinon elle renvoie None.\n",
    "\n",
    "* La fonction `search` recherche la première occurrence de l'expression régulière dans la chaîne de texte. Elle renvoie également un objet Match si une correspondance est trouvée, sinon elle renvoie None.\n",
    "\n",
    "* La fonction `findall` recherche toutes les occurrences de l'expression régulière dans la chaîne de texte et renvoie les correspondances sous forme de liste de chaînes de caractères.\n",
    "\n",
    "* La fonction `finditer` recherche toutes les occurrences de l'expression régulière dans la chaîne de texte et renvoie un itérable d'objets Match. Vous pouvez parcourir cet itérable pour obtenir les correspondances individuelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction match :\n",
      "Correspondance trouvée : Le\n",
      "<re.Match object; span=(0, 2), match='Le'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Le texte de recherche\n",
    "phrase = \"Le chat est reparti avec la souris.\"\n",
    "\n",
    "# match trouve une correspondance au début de la chaîne seulement\n",
    "match = re.match('Le', phrase)\n",
    "print(\"Fonction match :\")\n",
    "if match:\n",
    "    print(f\"Correspondance trouvée : {match.group()}\")\n",
    "    print(match)\n",
    "else:\n",
    "    print(\"Aucune correspondance trouvée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fonction search :\n",
      "Correspondance trouvée : souris\n",
      "<re.Match object; span=(28, 34), match='souris'>\n"
     ]
    }
   ],
   "source": [
    "# search trouve la première correspondance dans toute la chaîne\n",
    "search = re.search('souris', phrase)\n",
    "print(\"\\nFonction search :\")\n",
    "if search:\n",
    "    print(f\"Correspondance trouvée : {search.group()}\")\n",
    "    print(search)\n",
    "else:\n",
    "    print(\"Aucune correspondance trouvée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fonction findall :\n",
      "Correspondances trouvées : ['e', 'e', 'e', 'e']\n"
     ]
    }
   ],
   "source": [
    "# findall trouve toutes les correspondances dans la chaîne\n",
    "findall = re.findall('e', phrase)\n",
    "print(\"\\nFonction findall :\")\n",
    "if findall:\n",
    "    print(f\"Correspondances trouvées : {findall}\")\n",
    "else:\n",
    "    print(\"Aucune correspondance trouvée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fonction finditer :\n",
      "Correspondance trouvée : e at 1\n",
      "Correspondance trouvée : e at 8\n",
      "Correspondance trouvée : e at 13\n",
      "Correspondance trouvée : e at 22\n"
     ]
    }
   ],
   "source": [
    "# finditer trouve toutes les correspondances dans la chaine \n",
    "# et retourne un objet itérable de correspondances\n",
    "finditer = re.finditer('e', phrase)\n",
    "print(\"\\nFonction finditer :\")\n",
    "for match in finditer:\n",
    "    print(f\"Correspondance trouvée : {match.group()} at {match.start()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La différence entre `match` et `search`\n",
    "\n",
    "La fonction match essaie de trouver une correspondance dès le début de la chaîne. Si le motif ne correspond pas au début de la chaîne, match renvoie `None`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 7), match='Bonjour'>\n"
     ]
    }
   ],
   "source": [
    "texte = \"Bonjour, comment ça va ?\"\n",
    "match = re.match(\"Bonjour\", texte)\n",
    "print(match) # <re.Match object; span=(0, 7), match='Bonjour'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.match(\"comment\", texte)\n",
    "match"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En revanche, la fonction `search` cherche la première correspondance dans toute la chaîne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(9, 16), match='comment'>\n"
     ]
    }
   ],
   "source": [
    "texte = \"Bonjour, comment ça va ?\"\n",
    "search = re.search(\"comment\", texte)\n",
    "print(search) # <re.Match object; span=(9, 15), match='comment'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('12', 'chats', 'dans')]\n"
     ]
    }
   ],
   "source": [
    "# un exemple un peu plus compliqué\n",
    "texte = \"Il y a 12 chats dans la maison. 3 d'entre eux sont noirs et 9 sont blancs.\"\n",
    "pattern = r'(\\d+)\\s(chats|chiens)\\s(dans|sur)\\s\\w+'\n",
    "\n",
    "correspondances = re.findall(pattern, texte)\n",
    "print(correspondances)  # [('12', 'chats', 'dans')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet exemple, le pattern recherché est `(\\d+)\\s(chats|chiens)\\s(dans|sur)\\s\\w+`. \n",
    "\n",
    "Il contient :\n",
    "\n",
    "* `(\\d+)` : Un groupe de capture permettant de rechercher une série de un ou plusieurs chiffres.\n",
    "* `\\s`  : Un espace blanc.\n",
    "(chats|chiens) : Un groupe d'alternatives permettant de rechercher soit \"chats\" soit \"chiens\".\n",
    "* `\\s` : Un autre espace blanc.\n",
    "(dans|sur) : Un autre groupe d'alternatives permettant de rechercher soit \"dans\" soit \"sur\".\n",
    "* `\\s` : Un autre espace blanc.\n",
    "* `\\w+` : Un ou plusieurs caractères alphanumériques.\n",
    "Ce pattern recherche donc une chaîne de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
